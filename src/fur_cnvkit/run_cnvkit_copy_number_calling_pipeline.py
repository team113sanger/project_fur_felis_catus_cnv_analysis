import argparse
from concurrent.futures import ProcessPoolExecutor, as_completed
from pathlib import Path
import typing as t

import pandas as pd

from fur_cnvkit import constants
from fur_cnvkit.utils.fur_utils import (
    extract_metadata_files_from_parameter_json,
    get_sample_ids_for_file_list,
    map_sample_ids_to_study_ids,
    split_file_list_by_sample_sex,
    get_sample_specific_files,
    set_metadata_columns,
)
from fur_cnvkit.utils.cnvkit_utils import (
    run_cnvkit_batch,
    filter_unplaced_contigs_from_cnvkit_output_file,
    perform_centring,
    run_cnvkit_genemetrics,
    filter_genemetrics_file,
    filter_cns_by_weight,
    run_cnvkit_diagram,
    run_cnvkit_scatter,
)
from fur_cnvkit.calculate_mad import run_mad_calculation_pipeline
from fur_cnvkit.generate_genemetrics_study_summary import (
    generate_genemetrics_study_summary_csv,
)
from fur_cnvkit.utils.logging_utils import setup_logging, get_package_logger

# Set up logging
COMMAND_NAME: str = constants.COMMAND_NAME__RUN_CNVKIT_CN_CALLING_PIPELINE
logger = get_package_logger()


def get_argparser(
    subparser: t.Optional[argparse._SubParsersAction] = None,
) -> argparse.ArgumentParser:
    """
    Either returns a new ArgumentParser instance or a subparser for the
    run_cnvkit_copy_number_calling_pipeline command.

    It is preferrable to use the subparser argument as it unifies the CLI to a
    single entrypoint. To preserve backwards compatibility, the function can
    also be called without the subparser argument.
    """
    if subparser is None:
        parser = argparse.ArgumentParser(
            description=constants.DESCRIPTION__RUN_CNVKIT_CN_CALLING_PIPELINE
        )
    else:
        parser = subparser.add_parser(
            COMMAND_NAME,
            description=constants.DESCRIPTION__RUN_CNVKIT_CN_CALLING_PIPELINE,
            help=constants.SHORT_HELP__RUN_CNVKIT_CN_CALLING_PIPELINE,
        )

    # Parameter file path
    parser.add_argument(
        "-p",
        "--parameter_file",
        type=Path,
        required=True,
        help="Path to the parameter file generated by the generate_copy_number_reference.py script.",
    )
    # Male reference file path
    parser.add_argument(
        "-m",
        "--male_reference",
        type=Path,
        required=True,
        help="Path to the male copy number reference file.",
    )
    # Female reference file path
    parser.add_argument(
        "-f",
        "--female_reference",
        type=Path,
        required=True,
        help="Path to the female copy number reference file.",
    )
    # List of studies to process (if not provided, process all)
    parser.add_argument(
        "-s",
        "--studies",
        type=str,
        nargs="+",
        help="List of specific studies to process. If not provided, all studies will be processed.",
    )
    # Gain threshold for calling copy number gains
    parser.add_argument(
        "-gt",
        "--gain_threshold",
        type=float,
        default=0.585,
        help="Log2(FC) threshold for calling copy-number gains.",
    )
    # Loss threshold for calling copy number losses
    parser.add_argument(
        "-lt",
        "--loss_threshold",
        type=float,
        default=-0.4,
        help="Log2(FC) threshold for calling copy-number losses.",
    )
    parser.add_argument(
        "--weight_filter_threshold",
        type=float,
        help=(
            "If provided, segments with weight below this value will be removed from "
            "median-centred .cns files and additional plots will be generated from the "
            "filtered files."
        ),
    )
    # Output directory for results
    parser.add_argument(
        "-o",
        "--outdir",
        type=Path,
        required=True,
        help="Path to the output directory.",
    )
    parser.add_argument(
        "--study-workers",
        type=int,
        default=None,
        help=(
            "Maximum number of studies to process in parallel. "
            "If omitted, studies are processed sequentially."
        ),
    )
    parser.add_argument(
        "--batch-processes",
        type=int,
        default=None,
        help=(
            "Number of worker processes to supply to cnvkit.py batch via the --processes argument. "
            "If omitted, CNVkit will use all available CPUs for each study."
        ),
    )
    parser.add_argument(
        "--verbose",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        dest="verbose",
        help="log level",
    )
    return parser


def perform_post_processing(
    sample_id: str,
    sample_cnvkit_batch_output_files: t.List[Path],
    sex: str,
    gain_threshold: float,
    loss_threshold: float,
    weight_filter_threshold: t.Optional[float],
    log2_shift_records: t.List[t.Dict[str, t.Any]],
    outdir: Path,
):
    """
    Perform post-processing on CNVkit output files for a given sample.

    Steps:
      - Identify the ratio (.cnr) and call segment (.cns) files.
      - Run median centring on the segment file.
      - Store the log2 shift value from centring.
      - Run cnvkit genemetrics on both the ratio file and the median-centred segment file.
      - Filter the genemetrics output using specified thresholds.
      - Generate diagram and scatter plots.
      - If a weight filter threshold is provided, create a weight-filtered
        median-centred file and generate additional plots from it.

    Returns:
        A tuple of (filtered genemetrics segment file, ratio file) for later MAD calculation.
    """
    logger.info(f"Post-processing sample {sample_id} ...")

    # Identify the ratio (.cnr) file
    ratio_file = next(
        f for f in sample_cnvkit_batch_output_files if f.name.endswith(".cnr")
    )
    # Identify the call segment (.cns) file
    call_segment_file = next(
        f for f in sample_cnvkit_batch_output_files if f.name.endswith("call.cns")
    )

    logger.debug(f"Sample {sample_id} - Ratio file: {ratio_file}")
    logger.debug(f"Sample {sample_id} - Call segment file: {call_segment_file}")

    # Run median centring on the segment file and capture the log2 shift value.
    median_centred_segment_file, log2_shift_value = perform_centring(
        call_segment_file, outdir, centring_method="median"
    )
    logger.debug(
        f"Sample {sample_id} - Median centred segment file: {median_centred_segment_file}"
    )
    logger.debug(f"Sample {sample_id} - Log2 shift value: {log2_shift_value}")

    # Append the log2 shift information to the records list.
    log2_shift_records.append(
        {"Sample ID": sample_id, "Sex": sex, "Log2 Shift Value": log2_shift_value}
    )
    logger.debug(f"Log2 shift record appended for sample {sample_id}")

    # Run genemetrics on the ratio file.
    genemetrics_ratio_file = run_cnvkit_genemetrics(
        ratio_file=ratio_file,
        threshold=1e-9,  # Very low threshold to include all genes.
        min_probes=3,
        output_prefix=sample_id,
        outdir=outdir,
        sex=sex,
    )
    # Run genemetrics on the median-centred segment file.
    genemetrics_segment_file = run_cnvkit_genemetrics(
        ratio_file=ratio_file,
        threshold=1e-9,
        min_probes=3,
        output_prefix=sample_id,
        outdir=outdir,
        sex=sex,
        segment_file=median_centred_segment_file,
    )
    logger.debug(
        f"Sample {sample_id} - Genemetrics ratio file: {genemetrics_ratio_file}"
    )
    logger.debug(
        f"Sample {sample_id} - Genemetrics segment file: {genemetrics_segment_file}"
    )

    # Filter the genemetrics files to extract significant copy-number calls.
    filtered_genemetrics_ratio_file = filter_genemetrics_file(
        genemetrics_file=genemetrics_ratio_file,
        lower_threshold=loss_threshold,
        upper_threshold=gain_threshold,
        outdir=outdir,
    )
    filtered_genemetrics_segment_file = filter_genemetrics_file(
        genemetrics_file=genemetrics_segment_file,
        lower_threshold=loss_threshold,
        upper_threshold=gain_threshold,
        outdir=outdir,
    )
    logger.debug(
        f"Sample {sample_id} - Filtered genemetrics ratio file: {filtered_genemetrics_ratio_file}"
    )
    logger.debug(
        f"Sample {sample_id} - Filtered genemetrics segment file: {filtered_genemetrics_segment_file}"
    )

    # Generate plots (diagram and scatter) for visualization.
    diagram_plot = run_cnvkit_diagram(ratio_file, median_centred_segment_file, outdir)
    scatter_plot = run_cnvkit_scatter(ratio_file, median_centred_segment_file, outdir)
    logger.debug(f"Sample {sample_id} - Diagram plot: {diagram_plot}")
    logger.debug(f"Sample {sample_id} - Scatter plot: {scatter_plot}")

    if weight_filter_threshold is not None:
        weight_filtered_segment_file = filter_cns_by_weight(
            median_centred_segment_file, weight_filter_threshold, outdir
        )
        plot_tag = f"weight-ge-{weight_filter_threshold}"
        filtered_diagram_plot = run_cnvkit_diagram(
            ratio_file,
            weight_filtered_segment_file,
            outdir,
            output_tag=plot_tag,
        )
        filtered_scatter_plot = run_cnvkit_scatter(
            ratio_file,
            weight_filtered_segment_file,
            outdir,
            output_tag=plot_tag,
        )
        logger.debug(
            f"Sample {sample_id} - Weight-filtered segment file: {weight_filtered_segment_file}"
        )
        logger.debug(
            f"Sample {sample_id} - Filtered diagram plot: {filtered_diagram_plot}"
        )
        logger.debug(
            f"Sample {sample_id} - Filtered scatter plot: {filtered_scatter_plot}"
        )

    logger.info(f"Sample {sample_id} post-processing complete.")
    # Return the filtered genemetrics segment file and the ratio file (for MAD calculations).
    return filtered_genemetrics_segment_file, ratio_file


def process_sample(
    sample_id: str,
    cnvkit_batch_output_files: t.List[Path],
    unplaced_contigs: t.List[str],
    sex: str,
    gain_threshold: float,
    loss_threshold: float,
    weight_filter_threshold: t.Optional[float],
    log2_shift_records: t.List[t.Dict[str, t.Any]],
    batch_outdir: Path,
):
    """
    Process an individual sample.

    Steps:
      - Retrieve sample-specific CNVkit output files.
      - Filter out unplaced contig entries from text files.
      - Call post-processing function.

    Returns:
      A tuple (sample_id, genemetrics file, ratio file).
    """
    logger.info(f"Processing sample {sample_id} ...")

    # Get files specific to this sample.
    sample_files = get_sample_specific_files(cnvkit_batch_output_files, sample_id)
    logger.debug(f"Sample {sample_id} - CNVkit output files: {sample_files}")

    # Filter out unplaced contig data from text-based files.
    for file in sample_files:
        if file.name.endswith(".pdf") or file.name.endswith(".png"):
            continue
        filter_unplaced_contigs_from_cnvkit_output_file(file, unplaced_contigs)
        logger.debug(f"Filtered unplaced contigs in file: {file}")

    # Perform post-processing on the sample files.
    sample_genemetrics_file, ratio_file = perform_post_processing(
        sample_id=sample_id,
        sample_cnvkit_batch_output_files=sample_files,
        sex=sex,
        gain_threshold=gain_threshold,
        loss_threshold=loss_threshold,
        weight_filter_threshold=weight_filter_threshold,
        log2_shift_records=log2_shift_records,
        outdir=batch_outdir,
    )
    logger.info(f"Sample {sample_id} processed successfully.")
    return sample_id, sample_genemetrics_file, ratio_file


def process_sex_group(
    sex: str,
    sex_tumour_bams: t.List[Path],
    study_outdir: Path,
    male_ref: Path,
    female_ref: Path,
    unplaced_contigs: t.List[str],
    gain_threshold: float,
    loss_threshold: float,
    weight_filter_threshold: t.Optional[float],
    sample_metadata_xlsx: Path,
    log2_shift_records: t.List[t.Dict[str, t.Any]],
    cnvkit_batch_processes: t.Optional[int] = None,
):
    """
    Process all samples for a given sex group.

    Steps:
      - Run CNVkit batch processing on tumour BAMs for this sex.
      - Retrieve output files.
      - Process each sample individually.

    Returns:
      A list of tuples for each sample: (sample_id, genemetrics file, ratio file).
    """
    logger.info(f"Processing {sex} samples ...")
    # Choose the appropriate reference based on sex.
    copy_number_reference_file = male_ref if sex == "male" else female_ref
    logger.debug(f"{sex.capitalize()} reference file: {copy_number_reference_file}")

    # Run the CNVkit batch process and retrieve output directory.
    batch_output_dir = run_cnvkit_batch(
        tumour_bams=sex_tumour_bams,
        copy_number_reference_file=copy_number_reference_file,
        outdir=study_outdir,
        sex=sex,
        processes=cnvkit_batch_processes,
    )
    logger.debug(f"Batch output directory for {sex} samples: {batch_output_dir}")

    # List all files from the batch output.
    batch_output_files = [Path(f) for f in batch_output_dir.glob("*") if f.is_file()]
    # Get sample IDs from the tumour BAM files.
    sex_sample_ids = get_sample_ids_for_file_list(sex_tumour_bams)
    logger.info(f"Found {len(sex_sample_ids)} {sex} samples.")

    sex_genemetrics_records = []
    # Process each sample and store its record.
    for sample_id in sex_sample_ids:
        sample_record = process_sample(
            sample_id,
            batch_output_files,
            unplaced_contigs,
            sex,
            gain_threshold,
            loss_threshold,
            weight_filter_threshold,
            log2_shift_records,
            batch_output_dir,
        )
        sex_genemetrics_records.append(sample_record)
    return sex_genemetrics_records


def process_study(
    study_id: str,
    sample_ids: t.List[str],
    tumour_bam_list: t.List[Path],
    sample_metadata_xlsx: Path,
    unplaced_contigs: t.List[str],
    male_ref: Path,
    female_ref: Path,
    baitset_genes_file: Path,
    gain_threshold: float,
    loss_threshold: float,
    weight_filter_threshold: t.Optional[float],
    outdir: Path,
    cnvkit_batch_processes: t.Optional[int] = None,
):
    """
    Process an individual study through the complete CNVkit pipeline.

    Steps:
      - Create a study-specific output directory.
      - Filter tumour BAMs belonging to the study.
      - Split tumour BAMs by sex.
      - Process each sample.
      - Run the MAD calculation pipeline on all ratio (.cnr) files.
      - Filter out samples with the top 20% highest MAD.
      - Merge log2 shift values.
      - Generate a cohort-level genemetrics summary CSV using filtered samples.
    """
    logger.info(f"Processing study {study_id} ...")
    study_outdir = outdir / study_id
    study_outdir.mkdir(parents=True, exist_ok=True)
    logger.debug(f"Study output directory: {study_outdir}")

    # Filter tumour BAMs that belong to this study.
    study_tumour_bams = [
        bam
        for bam in tumour_bam_list
        if any(sample_id in bam.name for sample_id in sample_ids)
    ]
    logger.info(f"Study {study_id} - Found {len(study_tumour_bams)} tumour BAM files.")

    # Split the tumour BAMs by sex.
    tumour_bam_sex_dict = split_file_list_by_sample_sex(
        study_tumour_bams, sample_metadata_xlsx
    )
    logger.debug(f"Tumour BAMs split by sex: {tumour_bam_sex_dict}")

    log2_shift_records: t.List[t.Dict[str, t.Any]] = []
    # Store a tuple (sample_id, genemetrics file, ratio file) for each sample.
    study_genemetrics_records: t.List[t.Tuple[str, Path, Path]] = []

    # Process samples for each sex group.
    for sex, sex_tumour_bams in tumour_bam_sex_dict.items():
        sex_records = process_sex_group(
            sex,
            sex_tumour_bams,
            study_outdir,
            male_ref,
            female_ref,
            unplaced_contigs,
            gain_threshold,
            loss_threshold,
            weight_filter_threshold,
            sample_metadata_xlsx,
            log2_shift_records,
            cnvkit_batch_processes,
        )
        study_genemetrics_records += sex_records

    # --- MAD Calculation, Plotting, and Filtering ---
    # Collect all ratio (.cnr) files and their corresponding segment (.cns) files from the processed samples.
    cnr_files = [
        ratio_file
        for sample_id, genemetrics_file, ratio_file in study_genemetrics_records
    ]
    cns_files = [
        ratio_file.with_suffix(".cns")
        for sample_id, genemetrics_file, ratio_file in study_genemetrics_records
    ]
    # Run the MAD calculation pipeline which saves the results and generates a plot.
    filtered_sample_ids, mad_df = run_mad_calculation_pipeline(
        cnr_files=cnr_files,
        cns_files=cns_files,
        outdir=study_outdir,
        prefix=study_id,
    )

    # Filter out high-MAD samples from the study records.
    filtered_study_genemetrics_files = [
        genemetrics_file
        for sample_id, genemetrics_file, ratio_file in study_genemetrics_records
        if sample_id not in filtered_sample_ids
    ]
    logger.info(
        f"Filtered out {len(filtered_sample_ids)} high-MAD samples from study {study_id}."
    )

    # Merge the log2 shift records with an existing CSV if available.
    log2_shift_csv_path = study_outdir / "log2_shift_values.csv"
    if log2_shift_csv_path.exists():
        logger.info(
            f"Merging with existing log2 shift CSV at {log2_shift_csv_path} ..."
        )
        existing_df = pd.read_csv(log2_shift_csv_path)
        existing_log2_dict = {
            row["Sample ID"]: row["Log2 Shift Value"]
            for _, row in existing_df.iterrows()
            if pd.notnull(row["Log2 Shift Value"])
        }
        for record in log2_shift_records:
            if (
                record["Log2 Shift Value"] is None
                and record["Sample ID"] in existing_log2_dict
            ):
                record["Log2 Shift Value"] = existing_log2_dict[record["Sample ID"]]
    log2_shift_df = pd.DataFrame(log2_shift_records)
    log2_shift_df.to_csv(log2_shift_csv_path, index=False)
    logger.info(f"Log2 shift CSV saved at {log2_shift_csv_path}")

    # Generate the study-level genemetrics summary CSV using only filtered samples.
    generate_genemetrics_study_summary_csv(
        study_id=study_id,
        genemetrics_files=filtered_study_genemetrics_files,
        baitset_genes_file=baitset_genes_file,
        outdir=study_outdir,
        gain_threshold=gain_threshold,
        loss_threshold=loss_threshold,
    )

    # Also, generate the study-level genemetrics summary including all samples (for completeness).
    generate_genemetrics_study_summary_csv(
        study_id=f"{study_id}_all_samples",
        genemetrics_files=[
            genemetrics_file
            for sample_id, genemetrics_file, ratio_file in study_genemetrics_records
        ],
        baitset_genes_file=baitset_genes_file,
        outdir=study_outdir,
        gain_threshold=gain_threshold,
        loss_threshold=loss_threshold,
    )

    logger.info(f"Study {study_id} processing complete.")


def _normalize_worker_count(value: t.Optional[int]) -> t.Optional[int]:
    if value is None:
        return None
    return max(1, value)


def _process_studies(
    study_ids_to_sample_ids: t.Dict[str, t.List[str]],
    selected_studies: t.Optional[t.Set[str]],
    tumour_bam_list: t.List[Path],
    sample_metadata_xlsx: Path,
    unplaced_contigs: t.List[str],
    male_ref: Path,
    female_ref: Path,
    baitset_genes_file: Path,
    gain_threshold: float,
    loss_threshold: float,
    weight_filter_threshold: t.Optional[float],
    outdir: Path,
    study_workers: t.Optional[int],
    batch_processes: t.Optional[int],
):
    studies_to_process = [
        (study_id, sample_ids)
        for study_id, sample_ids in study_ids_to_sample_ids.items()
        if not selected_studies or study_id in selected_studies
    ]

    if study_workers is not None and study_workers > 1 and len(studies_to_process) > 1:
        logger.info(
            f"Processing {len(studies_to_process)} studies in parallel using "
            f"{study_workers} worker processes."
        )
        with ProcessPoolExecutor(max_workers=study_workers) as executor:
            future_to_study = {
                executor.submit(
                    process_study,
                    study_id,
                    sample_ids,
                    tumour_bam_list,
                    sample_metadata_xlsx,
                    unplaced_contigs,
                    male_ref,
                    female_ref,
                    baitset_genes_file,
                    gain_threshold,
                    loss_threshold,
                    weight_filter_threshold,
                    outdir,
                    batch_processes,
                ): study_id
                for study_id, sample_ids in studies_to_process
            }
            for future in as_completed(future_to_study):
                study_id = future_to_study[future]
                future.result()
                logger.info(f"Study {study_id} finished.")
    else:
        for study_id, sample_ids in studies_to_process:
            process_study(
                study_id,
                sample_ids,
                tumour_bam_list,
                sample_metadata_xlsx,
                unplaced_contigs,
                male_ref,
                female_ref,
                baitset_genes_file,
                gain_threshold,
                loss_threshold,
                weight_filter_threshold,
                outdir,
                batch_processes,
            )


def main(args: t.Optional[argparse.Namespace] = None):
    """
    Main entry point for the CNVkit pipeline.
    """
    if args is None:
        argparser = get_argparser()
        args = argparser.parse_args()
    logger.debug(f"Parsed arguments: {args}")

    parameter_file = args.parameter_file
    male_ref = args.male_reference
    female_ref = args.female_reference
    selected_studies = set(args.studies) if args.studies else None
    gain_threshold = args.gain_threshold
    loss_threshold = args.loss_threshold
    weight_filter_threshold = args.weight_filter_threshold
    outdir = args.outdir
    study_workers = _normalize_worker_count(args.study_workers)
    batch_processes = _normalize_worker_count(args.batch_processes)

    # Log the input parameters.
    logger.debug(f"Parameter file: {parameter_file}")
    logger.debug(f"Male reference: {male_ref}")
    logger.debug(f"Female reference: {female_ref}")
    logger.debug(f"Selected studies: {selected_studies}")
    logger.debug(f"Gain threshold: {gain_threshold}")
    logger.debug(f"Loss threshold: {loss_threshold}")
    logger.debug(f"Weight filter threshold: {weight_filter_threshold}")
    logger.debug(f"Output directory: {outdir}")
    logger.debug(f"Study workers: {study_workers}")
    logger.debug(f"CNVkit batch processes: {batch_processes}")

    logger.info("Starting CNVkit copy number calling pipeline ...")

    # Extract metadata from the parameter file.
    metadata = extract_metadata_files_from_parameter_json(parameter_file)
    set_metadata_columns(metadata.get("metadata_columns"))
    tumour_bam_list = metadata["tumour_bams"]
    sample_metadata_xlsx = metadata["sample_metadata_xlsx"]
    unplaced_contigs = metadata["unplaced_contig_prefixes"]
    baitset_genes_file = metadata["baitset_genes_file"]

    logger.debug(f"Tumour BAMs: {tumour_bam_list}")
    logger.debug(f"Sample metadata file: {sample_metadata_xlsx}")
    logger.debug(f"Unplaced contigs: {unplaced_contigs}")

    # Map tumour samples to studies.
    tumour_sample_ids = get_sample_ids_for_file_list(tumour_bam_list)
    study_ids_to_sample_ids = map_sample_ids_to_study_ids(
        tumour_sample_ids, sample_metadata_xlsx
    )
    logger.debug(f"Mapped study IDs to sample IDs: {study_ids_to_sample_ids}")

    # Check that all selected studies are present in the metadata.
    if selected_studies and not selected_studies.issubset(
        set(study_ids_to_sample_ids.keys())
    ):
        missing_studies = selected_studies - set(study_ids_to_sample_ids.keys())
        raise ValueError(
            f"Selected studies not found in metadata: {', '.join(missing_studies)}"
        )

    _process_studies(
        study_ids_to_sample_ids=study_ids_to_sample_ids,
        selected_studies=selected_studies,
        tumour_bam_list=tumour_bam_list,
        sample_metadata_xlsx=sample_metadata_xlsx,
        unplaced_contigs=unplaced_contigs,
        male_ref=male_ref,
        female_ref=female_ref,
        baitset_genes_file=baitset_genes_file,
        gain_threshold=gain_threshold,
        loss_threshold=loss_threshold,
        weight_filter_threshold=weight_filter_threshold,
        outdir=outdir,
        study_workers=study_workers,
        batch_processes=batch_processes,
    )

    logger.info("CNVkit pipeline execution complete.")
    return


if __name__ == "__main__":
    setup_logging()
    main()

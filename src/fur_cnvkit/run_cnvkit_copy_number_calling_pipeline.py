import argparse
from pathlib import Path
import typing as t

import pandas as pd

from fur_cnvkit import constants
from fur_cnvkit.utils.fur_utils import (
    extract_metadata_files_from_parameter_json,
    get_sample_id_from_file_path,
    get_sample_ids_for_file_list,
    map_sample_ids_to_study_ids,
    split_file_list_by_sample_sex,
    get_sample_specific_files,
)
from fur_cnvkit.utils.cnvkit_utils import (
    run_cnvkit_batch,
    filter_unplaced_contigs_from_cnvkit_output_file,
    perform_centring,
    run_cnvkit_genemetrics,
    filter_genemetrics_file,
    run_cnvkit_diagram,
    run_cnvkit_scatter,
)
from fur_cnvkit.calculate_mad import run_mad_calculation_pipeline
from fur_cnvkit.utils.logging_utils import (
    setup_logging,
    get_package_logger,
    logging_argparse_decorator,
)

# Set up logging
COMMAND_NAME: str = constants.COMMAND_NAME__RUN_CNVKIT_CN_CALLING_PIPELINE
logger = get_package_logger()


@logging_argparse_decorator
def get_argparser(
    subparser: t.Optional[argparse._SubParsersAction] = None,
) -> argparse.ArgumentParser:
    """
    Either returns a new ArgumentParser instance or a subparser for the
    run_cnvkit_copy_number_calling_pipeline command.

    It is preferrable to use the subparser argument as it unifies the CLI to a
    single entrypoint. To preserve backwards compatibility, the function can
    also be called without the subparser argument.
    """
    if subparser is None:
        parser = argparse.ArgumentParser(
            description=constants.DESCRIPTION__RUN_CNVKIT_CN_CALLING_PIPELINE
        )
    else:
        parser = subparser.add_parser(
            COMMAND_NAME,
            description=constants.DESCRIPTION__RUN_CNVKIT_CN_CALLING_PIPELINE,
            help=constants.SHORT_HELP__RUN_CNVKIT_CN_CALLING_PIPELINE,
        )

    parser = argparse.ArgumentParser(
        description="Run the CNVkit copy number calling pipeline."
    )
    # Parameter file path
    parser.add_argument(
        "-p",
        "--parameter_file",
        type=Path,
        required=True,
        help="Path to the parameter file generated by the generate_copy_number_reference.py script.",
    )
    # Male reference file path
    parser.add_argument(
        "-m",
        "--male_reference",
        type=Path,
        required=True,
        help="Path to the male copy number reference file.",
    )
    # Female reference file path
    parser.add_argument(
        "-f",
        "--female_reference",
        type=Path,
        required=True,
        help="Path to the female copy number reference file.",
    )
    # List of studies to process (if not provided, process all)
    parser.add_argument(
        "-s",
        "--studies",
        type=str,
        nargs="+",
        help="List of specific studies to process. If not provided, all studies will be processed.",
    )
    # Gain threshold for calling copy number gains
    parser.add_argument(
        "-gt",
        "--gain_threshold",
        type=float,
        default=0.585,
        help="Log2(FC) threshold for calling copy-number gains.",
    )
    # Loss threshold for calling copy number losses
    parser.add_argument(
        "-lt",
        "--loss_threshold",
        type=float,
        default=-0.4,
        help="Log2(FC) threshold for calling copy-number losses.",
    )
    # Output directory for results
    parser.add_argument(
        "-o",
        "--outdir",
        type=Path,
        required=True,
        help="Path to the output directory.",
    )
    return parser


def perform_post_processing(
    sample_id: str,
    sample_cnvkit_batch_output_files: t.List[Path],
    sex: str,
    gain_threshold: float,
    loss_threshold: float,
    log2_shift_records: t.List[t.Dict[str, t.Any]],
    outdir: Path,
):
    """
    Perform post-processing on CNVkit output files for a given sample.

    Steps:
      - Identify the ratio (.cnr) and call segment (.cns) files.
      - Run median centring on the segment file.
      - Store the log2 shift value from centring.
      - Run cnvkit genemetrics on both the ratio file and the median-centred segment file.
      - Filter the genemetrics output using specified thresholds.
      - Generate diagram and scatter plots.

    Returns:
        A tuple of (filtered genemetrics segment file, ratio file) for later MAD calculation.
    """
    logger.info(f"Post-processing sample {sample_id} ...")

    # Identify the ratio (.cnr) file
    ratio_file = next(
        f for f in sample_cnvkit_batch_output_files if f.name.endswith(".cnr")
    )
    # Identify the call segment (.cns) file
    call_segment_file = next(
        f for f in sample_cnvkit_batch_output_files if f.name.endswith("call.cns")
    )

    logger.debug(f"Sample {sample_id} - Ratio file: {ratio_file}")
    logger.debug(f"Sample {sample_id} - Call segment file: {call_segment_file}")

    # Run median centring on the segment file and capture the log2 shift value.
    median_centred_segment_file, log2_shift_value = perform_centring(
        call_segment_file, outdir, centring_method="median"
    )
    logger.debug(
        f"Sample {sample_id} - Median centred segment file: {median_centred_segment_file}"
    )
    logger.debug(f"Sample {sample_id} - Log2 shift value: {log2_shift_value}")

    # Append the log2 shift information to the records list.
    log2_shift_records.append(
        {"Sample ID": sample_id, "Sex": sex, "Log2 Shift Value": log2_shift_value}
    )
    logger.debug(f"Log2 shift record appended for sample {sample_id}")

    # Run genemetrics on the ratio file.
    genemetrics_ratio_file = run_cnvkit_genemetrics(
        ratio_file=ratio_file,
        threshold=1e-9,  # Very low threshold to include all genes.
        min_probes=3,
        output_prefix=sample_id,
        outdir=outdir,
        sex=sex,
    )
    # Run genemetrics on the median-centred segment file.
    genemetrics_segment_file = run_cnvkit_genemetrics(
        ratio_file=ratio_file,
        threshold=1e-9,
        min_probes=3,
        output_prefix=sample_id,
        outdir=outdir,
        sex=sex,
        segment_file=median_centred_segment_file,
    )
    logger.debug(
        f"Sample {sample_id} - Genemetrics ratio file: {genemetrics_ratio_file}"
    )
    logger.debug(
        f"Sample {sample_id} - Genemetrics segment file: {genemetrics_segment_file}"
    )

    # Filter the genemetrics files to extract significant copy-number calls.
    filtered_genemetrics_ratio_file = filter_genemetrics_file(
        genemetrics_file=genemetrics_ratio_file,
        lower_threshold=loss_threshold,
        upper_threshold=gain_threshold,
        outdir=outdir,
    )
    filtered_genemetrics_segment_file = filter_genemetrics_file(
        genemetrics_file=genemetrics_segment_file,
        lower_threshold=loss_threshold,
        upper_threshold=gain_threshold,
        outdir=outdir,
    )
    logger.debug(
        f"Sample {sample_id} - Filtered genemetrics ratio file: {filtered_genemetrics_ratio_file}"
    )
    logger.debug(
        f"Sample {sample_id} - Filtered genemetrics segment file: {filtered_genemetrics_segment_file}"
    )

    # Generate plots (diagram and scatter) for visualization.
    diagram_plot = run_cnvkit_diagram(ratio_file, median_centred_segment_file, outdir)
    scatter_plot = run_cnvkit_scatter(ratio_file, median_centred_segment_file, outdir)
    logger.debug(f"Sample {sample_id} - Diagram plot: {diagram_plot}")
    logger.debug(f"Sample {sample_id} - Scatter plot: {scatter_plot}")

    logger.info(f"Sample {sample_id} post-processing complete.")
    # Return the filtered genemetrics segment file and the ratio file (for MAD calculations).
    return filtered_genemetrics_segment_file, ratio_file


def process_sample(
    sample_id: str,
    cnvkit_batch_output_files: t.List[Path],
    unplaced_contigs: t.List[str],
    sex: str,
    gain_threshold: float,
    loss_threshold: float,
    log2_shift_records: t.List[t.Dict[str, t.Any]],
    batch_outdir: Path,
):
    """
    Process an individual sample.

    Steps:
      - Retrieve sample-specific CNVkit output files.
      - Filter out unplaced contig entries from text files.
      - Call post-processing function.

    Returns:
      A tuple (sample_id, genemetrics file, ratio file).
    """
    logger.info(f"Processing sample {sample_id} ...")

    # Get files specific to this sample.
    sample_files = get_sample_specific_files(cnvkit_batch_output_files, sample_id)
    logger.debug(f"Sample {sample_id} - CNVkit output files: {sample_files}")

    # Filter out unplaced contig data from text-based files.
    for file in sample_files:
        if file.name.endswith(".pdf") or file.name.endswith(".png"):
            continue
        filter_unplaced_contigs_from_cnvkit_output_file(file, unplaced_contigs)
        logger.debug(f"Filtered unplaced contigs in file: {file}")

    # Perform post-processing on the sample files.
    sample_genemetrics_file, ratio_file = perform_post_processing(
        sample_id=sample_id,
        sample_cnvkit_batch_output_files=sample_files,
        sex=sex,
        gain_threshold=gain_threshold,
        loss_threshold=loss_threshold,
        log2_shift_records=log2_shift_records,
        outdir=batch_outdir,
    )
    logger.info(f"Sample {sample_id} processed successfully.")
    return sample_id, sample_genemetrics_file, ratio_file


def process_sex_group(
    sex: str,
    sex_tumour_bams: t.List[Path],
    study_outdir: Path,
    male_ref: Path,
    female_ref: Path,
    unplaced_contigs: t.List[str],
    gain_threshold: float,
    loss_threshold: float,
    sample_metadata_xlsx: Path,
    log2_shift_records: t.List[t.Dict[str, t.Any]],
):
    """
    Process all samples for a given sex group.

    Steps:
      - Run CNVkit batch processing on tumour BAMs for this sex.
      - Retrieve output files.
      - Process each sample individually.

    Returns:
      A list of tuples for each sample: (sample_id, genemetrics file, ratio file).
    """
    logger.info(f"Processing {sex} samples ...")
    # Choose the appropriate reference based on sex.
    copy_number_reference_file = male_ref if sex == "male" else female_ref
    logger.debug(f"{sex.capitalize()} reference file: {copy_number_reference_file}")

    # Run the CNVkit batch process and retrieve output directory.
    batch_output_dir = run_cnvkit_batch(
        tumour_bams=sex_tumour_bams,
        copy_number_reference_file=copy_number_reference_file,
        outdir=study_outdir,
        sex=sex,
    )
    logger.debug(f"Batch output directory for {sex} samples: {batch_output_dir}")

    # List all files from the batch output.
    batch_output_files = [Path(f) for f in batch_output_dir.glob("*") if f.is_file()]
    # Get sample IDs from the tumour BAM files.
    sex_sample_ids = get_sample_ids_for_file_list(sex_tumour_bams)
    logger.info(f"Found {len(sex_sample_ids)} {sex} samples.")

    sex_genemetrics_records = []
    # Process each sample and store its record.
    for sample_id in sex_sample_ids:
        sample_record = process_sample(
            sample_id,
            batch_output_files,
            unplaced_contigs,
            sex,
            gain_threshold,
            loss_threshold,
            log2_shift_records,
            batch_output_dir,
        )
        sex_genemetrics_records.append(sample_record)
    return sex_genemetrics_records


def generate_genemetrics_study_summary_csv(
    study_id: str,
    genemetrics_files: t.List[Path],
    baitset_genes_file: Path,
    outdir: Path,
) -> pd.DataFrame:
    """
    Generate a study-level CSV summarizing genemetrics data.

    Steps:
      - Read baitset gene symbols.
      - Process each sample's genemetrics file to extract gene-level log2 data.
      - Aggregate duplicate gene entries by computing the mean.
      - Concatenate all sample data into a cohort-level DataFrame.
      - Save the DataFrame as a CSV.

    Returns:
      The cohort DataFrame.
    """
    logger.info(f"Generating study summary CSV for study {study_id} ...")
    output_csv_file_name = f"{study_id}.genemetrics_study_summary.csv"
    output_csv_file_path = outdir / output_csv_file_name
    logger.debug(f"Output CSV path: {output_csv_file_path}")

    # Load baitset genes.
    with open(baitset_genes_file, "r") as f:
        baitset_genes_list = [line.strip() for line in f.readlines()]
    logger.debug(f"Baitset genes (first 5): {baitset_genes_list[:5]}")

    sample_series_list = []
    # Labels to skip in the genemetrics file.
    skip_labels = {"none", "unk", "incmpl", "cmpl"}

    # Process each genemetrics file.
    for genemetrics_file in genemetrics_files:
        sample_id = get_sample_id_from_file_path(genemetrics_file)
        logger.info(f"Processing genemetrics file for sample {sample_id} ...")
        df_temp = pd.read_csv(genemetrics_file, sep="\t", usecols=[0, 4])
        logger.debug(f"Initial data for sample {sample_id}:\n{df_temp.head()}")

        # Filter out unwanted labels.
        df_temp = df_temp[~df_temp["gene"].isin(skip_labels)]
        # Convert log2 values to numeric.
        df_temp["log2"] = pd.to_numeric(df_temp["log2"], errors="coerce")
        # Aggregate duplicate gene entries by taking the mean.
        df_temp = df_temp.groupby("gene", as_index=False).mean()
        # Set the gene column as the index.
        df_temp.set_index("gene", inplace=True)
        # Reindex the DataFrame based on the baitset gene list.
        df_temp = df_temp.reindex(baitset_genes_list)
        # Rename the log2 column series to the sample_id.
        s = df_temp["log2"].rename(sample_id)
        sample_series_list.append(s)

    # Concatenate sample Series into a cohort DataFrame (samples are rows).
    cohort_df = pd.concat(sample_series_list, axis=1).T
    cohort_df.to_csv(output_csv_file_path)
    logger.info(f"Study summary CSV created at {output_csv_file_path}")
    return cohort_df


def process_study(
    study_id: str,
    sample_ids: t.List[str],
    tumour_bam_list: t.List[Path],
    sample_metadata_xlsx: Path,
    unplaced_contigs: t.List[str],
    male_ref: Path,
    female_ref: Path,
    baitset_genes_file: Path,
    gain_threshold: float,
    loss_threshold: float,
    outdir: Path,
):
    """
    Process an individual study through the complete CNVkit pipeline.

    Steps:
      - Create a study-specific output directory.
      - Filter tumour BAMs belonging to the study.
      - Split tumour BAMs by sex.
      - Process each sample.
      - Run the MAD calculation pipeline on all ratio (.cnr) files.
      - Filter out samples with the top 20% highest MAD.
      - Merge log2 shift values.
      - Generate a cohort-level genemetrics summary CSV using filtered samples.
    """
    logger.info(f"Processing study {study_id} ...")
    study_outdir = outdir / study_id
    study_outdir.mkdir(parents=True, exist_ok=True)
    logger.debug(f"Study output directory: {study_outdir}")

    # Filter tumour BAMs that belong to this study.
    study_tumour_bams = [
        bam
        for bam in tumour_bam_list
        if any(sample_id in bam.name for sample_id in sample_ids)
    ]
    logger.info(f"Study {study_id} - Found {len(study_tumour_bams)} tumour BAM files.")

    # Split the tumour BAMs by sex.
    tumour_bam_sex_dict = split_file_list_by_sample_sex(
        study_tumour_bams, sample_metadata_xlsx
    )
    logger.debug(f"Tumour BAMs split by sex: {tumour_bam_sex_dict}")

    log2_shift_records: t.List[t.Dict[str, t.Any]] = []
    # Store a tuple (sample_id, genemetrics file, ratio file) for each sample.
    study_genemetrics_records: t.List[t.Tuple[str, Path, Path]] = []

    # Process samples for each sex group.
    for sex, sex_tumour_bams in tumour_bam_sex_dict.items():
        sex_records = process_sex_group(
            sex,
            sex_tumour_bams,
            study_outdir,
            male_ref,
            female_ref,
            unplaced_contigs,
            gain_threshold,
            loss_threshold,
            sample_metadata_xlsx,
            log2_shift_records,
        )
        study_genemetrics_records += sex_records

    # --- MAD Calculation, Plotting, and Filtering ---
    # Collect all ratio (.cnr) files and their corresponding segment (.cns) files from the processed samples.
    cnr_files = [
        ratio_file
        for sample_id, genemetrics_file, ratio_file in study_genemetrics_records
    ]
    cns_files = [
        ratio_file.with_suffix(".cns")
        for sample_id, genemetrics_file, ratio_file in study_genemetrics_records
    ]
    # Run the MAD calculation pipeline which saves the results and generates a plot.
    filtered_sample_ids, mad_df = run_mad_calculation_pipeline(
        cnr_files=cnr_files,
        cns_files=cns_files,
        outdir=study_outdir,
        prefix=study_id,
    )

    # Filter out high-MAD samples from the study records.
    filtered_study_genemetrics_files = [
        genemetrics_file
        for sample_id, genemetrics_file, ratio_file in study_genemetrics_records
        if sample_id not in filtered_sample_ids
    ]
    logger.info(
        f"Filtered out {len(filtered_sample_ids)} high-MAD samples from study {study_id}."
    )

    # Merge the log2 shift records with an existing CSV if available.
    log2_shift_csv_path = study_outdir / "log2_shift_values.csv"
    if log2_shift_csv_path.exists():
        logger.info(
            f"Merging with existing log2 shift CSV at {log2_shift_csv_path} ..."
        )
        existing_df = pd.read_csv(log2_shift_csv_path)
        existing_log2_dict = {
            row["Sample ID"]: row["Log2 Shift Value"]
            for _, row in existing_df.iterrows()
            if pd.notnull(row["Log2 Shift Value"])
        }
        for record in log2_shift_records:
            if (
                record["Log2 Shift Value"] is None
                and record["Sample ID"] in existing_log2_dict
            ):
                record["Log2 Shift Value"] = existing_log2_dict[record["Sample ID"]]
    log2_shift_df = pd.DataFrame(log2_shift_records)
    log2_shift_df.to_csv(log2_shift_csv_path, index=False)
    logger.info(f"Log2 shift CSV saved at {log2_shift_csv_path}")

    # Generate the study-level genemetrics summary CSV using only filtered samples.
    generate_genemetrics_study_summary_csv(
        study_id=study_id,
        genemetrics_files=filtered_study_genemetrics_files,
        baitset_genes_file=baitset_genes_file,
        outdir=study_outdir,
    )
    logger.info(f"Study {study_id} processing complete.")


def main(args: t.Optional[argparse.Namespace] = None):
    """
    Main entry point for the CNVkit pipeline.
    """
    if args is None:
        argparser = get_argparser()
        args = argparser.parse_args()
    logger.debug(f"Parsed arguments: {args}")

    parameter_file = args.parameter_file
    male_ref = args.male_reference
    female_ref = args.female_reference
    selected_studies = set(args.studies) if args.studies else None
    gain_threshold = args.gain_threshold
    loss_threshold = args.loss_threshold
    outdir = args.outdir

    # Log the input parameters.
    logger.debug(f"Parameter file: {parameter_file}")
    logger.debug(f"Male reference: {male_ref}")
    logger.debug(f"Female reference: {female_ref}")
    logger.debug(f"Selected studies: {selected_studies}")
    logger.debug(f"Gain threshold: {gain_threshold}")
    logger.debug(f"Loss threshold: {loss_threshold}")
    logger.debug(f"Output directory: {outdir}")

    logger.info("Starting CNVkit copy number calling pipeline ...")

    # Extract metadata from the parameter file.
    metadata = extract_metadata_files_from_parameter_json(parameter_file)
    tumour_bam_list = metadata["tumour_bams"]
    sample_metadata_xlsx = metadata["sample_metadata_xlsx"]
    unplaced_contigs = metadata["unplaced_contig_prefixes"]
    baitset_genes_file = metadata["baitset_genes_file"]

    logger.debug(f"Tumour BAMs: {tumour_bam_list}")
    logger.debug(f"Sample metadata file: {sample_metadata_xlsx}")
    logger.debug(f"Unplaced contigs: {unplaced_contigs}")

    # Map tumour samples to studies.
    tumour_sample_ids = get_sample_ids_for_file_list(tumour_bam_list)
    study_ids_to_sample_ids = map_sample_ids_to_study_ids(
        tumour_sample_ids, sample_metadata_xlsx
    )
    logger.debug(f"Mapped study IDs to sample IDs: {study_ids_to_sample_ids}")

    # Check that all selected studies are present in the metadata.
    if selected_studies and not selected_studies.issubset(
        set(study_ids_to_sample_ids.keys())
    ):
        missing_studies = selected_studies - set(study_ids_to_sample_ids.keys())
        raise ValueError(
            f"Selected studies not found in metadata: {', '.join(missing_studies)}"
        )

    # Process each study.
    for study_id, sample_ids in study_ids_to_sample_ids.items():
        if selected_studies and study_id not in selected_studies:
            continue
        process_study(
            study_id,
            sample_ids,
            tumour_bam_list,
            sample_metadata_xlsx,
            unplaced_contigs,
            male_ref,
            female_ref,
            baitset_genes_file,
            gain_threshold,
            loss_threshold,
            outdir,
        )

    logger.info("CNVkit pipeline execution complete.")
    return


if __name__ == "__main__":
    setup_logging()
    main()
